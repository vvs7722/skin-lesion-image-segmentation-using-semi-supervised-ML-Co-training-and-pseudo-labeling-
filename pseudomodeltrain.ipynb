{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # os functionalities\n",
    "import random # generation of random numbers\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from sklearn import metrics # create ROC curve\n",
    "from matplotlib import pyplot as plt # image visualization\n",
    "\n",
    "# Tensorflow & Keras\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# Image manipulation\n",
    "from skimage import io\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable declaration\n",
    "input_dir = r\"C:\\Users\\arunm\\thusharproj\\test\\2018LA_Seg_Training Set\\images\\train3\"\n",
    "target_dir = r\"C:\\Users\\arunm\\thusharproj\\test\\final_pseudo_labels\"\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "img_size = (160,160)\n",
    "learning_rate = 0.001\n",
    "optimizer = \"RMSprop\"\n",
    "data_augmentation = False\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "num_classes = 2 # 0 - 1 / lesion - no lesion\n",
    "\n",
    "# Percentages of images going to train - val - test sets\n",
    "percentage_test = 0.05\n",
    "percentage_validation = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to the training and target images\n",
    "input_img_paths = sorted([\n",
    "    os.path.join(input_dir, fname)\n",
    "    for fname in os.listdir(input_dir)\n",
    "    if fname.endswith(\".jpg\")])\n",
    "\n",
    "target_img_paths = sorted([\n",
    "    os.path.join(target_dir, fname)\n",
    "    for fname in os.listdir(target_dir)\n",
    "    if fname.endswith(\".png\") and not fname.startswith(\".\")])\n",
    "\n",
    "# Check if dimentions are equal\n",
    "print(\"Number of samples in the training set:\", len(input_img_paths))\n",
    "print(\"Number of samples in the target set:\", len(target_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training images and get their shape\n",
    "image_to_visualize = 500\n",
    "img1 = io.imread(input_img_paths[image_to_visualize])\n",
    "img_shape = np.shape(img1)\n",
    "print(f\"The shape of the pictures in the training set is: {img_shape}\")\n",
    "\n",
    "# Read target images and get their shape\n",
    "img1 = io.imread(target_img_paths[image_to_visualize])\n",
    "img_shape = np.shape(img1)\n",
    "print(f\"The shape of the pictures in the target set is: {img_shape}\")\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Cetting values to rows and column variables\n",
    "rows = 1\n",
    "columns = 2\n",
    "\n",
    "# Plot images - Visualize an image and it's segmentation\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(io.imread(input_img_paths[image_to_visualize]))\n",
    "plt.title(\"Original image\")\n",
    "\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(io.imread(target_img_paths[image_to_visualize]), cmap='gray')\n",
    "plt.title(\"Segmentation mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionSegmentation(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, data_augmentation):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "        self.data_augmentation = data_augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        \n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        \n",
    "        if self.data_augmentation:\n",
    "            x = np.zeros((self.batch_size * 2,) + self.img_size + (3,), dtype=\"float32\")\n",
    "            y = np.zeros((self.batch_size * 2,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "            \n",
    "            for j, path in enumerate(batch_input_img_paths):\n",
    "                img = load_img(path, target_size=self.img_size)\n",
    "                img_target = load_img(batch_target_img_paths[j], target_size=self.img_size, color_mode=\"grayscale\")\n",
    "                img_target2 = load_img(batch_target_img_paths[j], target_size=self.img_size)\n",
    "                \n",
    "                # Convert PIL Images to NumPy arrays\n",
    "                img_array = np.array(img)\n",
    "                img_target_array = np.array(img_target)\n",
    "                img_target2_array = np.array(img_target2)\n",
    "                \n",
    "                # Apply data augmentation\n",
    "                img_augmented, img_target_augmented = self.generate_data_augmentation(img_array, img_target2_array)\n",
    "                \n",
    "                # Normalize and assign images\n",
    "                x[j] = tf.cast(img_array, tf.float32) / 255.0\n",
    "                y[j] = (np.expand_dims(img_target_array, 2) / 255).astype(int)\n",
    "                x[self.batch_size + j] = tf.cast(img_augmented, tf.float32) / 255.0\n",
    "                \n",
    "                # Convert augmented target to grayscale if necessary and assign\n",
    "                img_target_augmented = tf.image.rgb_to_grayscale(img_target_augmented)\n",
    "                y[self.batch_size + j] = (img_target_augmented.numpy() / 255).astype(int)\n",
    "        \n",
    "        else:\n",
    "            x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "            y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "            \n",
    "            for j, path in enumerate(batch_input_img_paths):\n",
    "                img = load_img(path, target_size=self.img_size)\n",
    "                img_target = load_img(batch_target_img_paths[j], target_size=self.img_size, color_mode=\"grayscale\")\n",
    "                \n",
    "                # Convert PIL Images to NumPy arrays\n",
    "                img_array = np.array(img)\n",
    "                img_target_array = np.array(img_target)\n",
    "                \n",
    "                # Normalize and assign images\n",
    "                x[j] = tf.cast(img_array, tf.float32) / 255.0\n",
    "                y[j] = (np.expand_dims(img_target_array, 2) / 255).astype(int)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    \n",
    "    \n",
    "    def generate_data_augmentation(self, img_orig, mask_orig):\n",
    "        \"\"\"Custom data augmentation function whose purpose is to generate new images by modifying the images already \n",
    "        present in the dataset. The fact that the function is custom respons to the imposibility of finding an adequate\n",
    "        utility in Tensorflow for this pupose that is able to modify both the images and the segmentations in the same way.\"\"\"\n",
    "        \n",
    "        # Zoom\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img_orig = tf.image.central_crop(img_orig, 0.75)\n",
    "            mask_orig = tf.image.central_crop(mask_orig, 0.75)\n",
    "            img_orig = tf.image.resize(img_orig, self.img_size)\n",
    "            mask_orig = tf.image.resize(mask_orig, self.img_size)\n",
    "\n",
    "        # Random brightness adjustment illumination\n",
    "        img_orig = tf.image.random_brightness(img_orig, 0.3)\n",
    "        \n",
    "        # Random contrast adjustment\n",
    "        img_orig = tf.image.random_contrast(img_orig, 0.2, 0.5)\n",
    "\n",
    "        # Flipping random horizontal or vertical\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img_orig = tf.image.flip_left_right(img_orig)\n",
    "            input_mask = tf.image.flip_left_right(mask_orig)\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img_orig = tf.image.flip_up_down(img_orig)\n",
    "            input_mask = tf.image.flip_up_down(mask_orig)\n",
    "\n",
    "        # Rotation in 30Â° steps\n",
    "        rot_factor = tf.cast(tf.random.uniform(shape=[], maxval=12, dtype=tf.int32), tf.float32)\n",
    "        angle = np.pi/12*rot_factor\n",
    "        img_orig = tfa.image.rotate(img_orig, angle)\n",
    "        mask_orig = tfa.image.rotate(mask_orig, angle)\n",
    "        \n",
    "        return img_orig, mask_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our img paths into a training validation and test sets\n",
    "random.Random(1337).shuffle(input_img_paths)\n",
    "random.Random(1337).shuffle(target_img_paths)\n",
    "\n",
    "test_samples = int(len(input_img_paths)*percentage_test)\n",
    "train_input_img_paths = input_img_paths[:-test_samples]\n",
    "train_target_img_paths = target_img_paths[:-test_samples]\n",
    "test_input_img_paths = input_img_paths[-test_samples:]\n",
    "test_target_img_paths = target_img_paths[-test_samples:]\n",
    "\n",
    "val_samples = int(len(train_input_img_paths)*percentage_validation)\n",
    "val_input_img_paths = train_input_img_paths[-val_samples:]\n",
    "val_target_img_paths = train_target_img_paths[-val_samples:]\n",
    "train_input_img_paths = train_input_img_paths[:-val_samples]\n",
    "train_target_img_paths = train_target_img_paths[:-val_samples]\n",
    "\n",
    "print(f\"Samples in train: {len(train_input_img_paths)}\")\n",
    "print(f\"Samples in validation: {len(val_input_img_paths)}\")\n",
    "print(f\"Samples in test: {len(test_input_img_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data Sequences for each split\n",
    "train_gen = LesionSegmentation(batch_size, img_size, train_input_img_paths, train_target_img_paths, data_augmentation)\n",
    "val_gen = LesionSegmentation(batch_size, img_size, val_input_img_paths, val_target_img_paths, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "    \n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimizer\n",
    "if optimizer == \"SGD\": # SGD\n",
    "    fit_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, decay=learning_rate/epochs)\n",
    "elif optimizer == \"RMSprop\": # RMSprop\n",
    "    fit_optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate, decay=learning_rate/epochs)\n",
    "else:  # Adam\n",
    "    fit_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-8, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training\n",
    "model.compile(optimizer=fit_optimizer, loss=loss_function)\n",
    "\n",
    "# Save the best model during training\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"pseudofinal_lesion_segmentation.h5\", save_best_only=True)]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "model_history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)\n",
    "\n",
    "# Serialize and save the model architecture to JSON\n",
    "model2_json = model.to_json()\n",
    "with open(\"pseudofinal_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model2_json)\n",
    "\n",
    "# Serialize and save the model weights to HDF5\n",
    "model.save_weights(\"pseudofinal_model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss while training\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
    "plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.savefig('Training and validation loss.jpg', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = LesionSegmentation(batch_size, img_size, test_input_img_paths, test_target_img_paths, False)\n",
    "test_preds = model.predict(test_gen)\n",
    "\n",
    "jaccard_scores = []\n",
    "dice_scores = []\n",
    "pixel_accuracy = []\n",
    "sensitivity = []\n",
    "specitivity = []\n",
    " \n",
    "predictions_formatted = []\n",
    "ground_truth_formatted = []\n",
    "    \n",
    "for i in range(0, len(test_preds)):\n",
    "    # Adapt prediction and ground truth\n",
    "    prediction = np.argmax(test_preds[i], axis=-1)\n",
    "    prediction = np.expand_dims(prediction, axis=-1)\n",
    "    predictions_formatted.append(prediction.flatten())\n",
    "    ground_truth = np.array(load_img(test_target_img_paths[i], target_size=img_size, color_mode=\"grayscale\"))\n",
    "    ground_truth = (np.expand_dims(ground_truth, 2)/255).astype(int)\n",
    "    ground_truth_formatted.append(ground_truth.flatten())\n",
    "    number_of_pixels = img_size[0]*img_size[1]    \n",
    "    \n",
    "    # Get Jaccard score\n",
    "    intersection = np.logical_and(ground_truth, prediction)\n",
    "    union = np.logical_or(ground_truth, prediction)\n",
    "    jaccard_scores.append(np.sum(intersection) / np.sum(union))  \n",
    "    \n",
    "    # Get Dice coefficient\n",
    "    intersection = np.sum(ground_truth.flatten() == prediction.flatten())\n",
    "    dice_scores.append((2 * np.sum(intersection) ) / (number_of_pixels + number_of_pixels))\n",
    "    \n",
    "    # Pixel-based metrics\n",
    "    equal_pixels = 0\n",
    "    number_of_true_positives = 0\n",
    "    number_of_true_negatives = 0\n",
    "    number_of_false_negatives = 0\n",
    "    number_of_false_positives = 0\n",
    "    \n",
    "    for row in range(len(ground_truth)):\n",
    "        for column in range(len(ground_truth[row])):\n",
    "            \n",
    "            if prediction[row][column] == ground_truth[row][column]:\n",
    "                equal_pixels += 1\n",
    "                \n",
    "            if ground_truth[row][column] == 1 and prediction[row][column] == ground_truth[row][column]:\n",
    "                number_of_true_positives += 1\n",
    "                \n",
    "            if ground_truth[row][column] == 0 and prediction[row][column] == ground_truth[row][column]:\n",
    "                number_of_true_negatives +=1\n",
    "            \n",
    "            if prediction[row][column] == 1 and prediction[row][column] != ground_truth[row][column]:\n",
    "                number_of_false_positives += 1\n",
    "            \n",
    "            if prediction[row][column] == 0 and prediction[row][column] != ground_truth[row][column]:\n",
    "                number_of_false_negatives += 1\n",
    "                \n",
    "    # Pixel accuracy: (Correct predictions / Number of predictions)      \n",
    "    pixel_accuracy.append(equal_pixels / number_of_pixels)\n",
    "    # Sensitivity - Recall: True positive rate (True positives / True positives + False negatives). How many of the positives are correct\n",
    "    try:sensitivity.append(number_of_true_positives / (number_of_true_positives + number_of_false_negatives))\n",
    "    except:sensitivity.append(0)\n",
    "    # Specitivity - True negative rate (True negative / True negative + False positives). How many of the negatives are correct\n",
    "    try: specitivity.append(number_of_true_negatives / (number_of_true_negatives + number_of_false_positives))\n",
    "    except: specitivity.append(0)\n",
    "        \n",
    "print(f\"Jaccard Score: {np.mean(jaccard_scores)} \\nDice Score: {np.mean(dice_scores)} \\nPixel accuracy: {np.mean(pixel_accuracy)} \\nSensitivity: {np.mean(sensitivity)} \\nSpecificity: {np.mean(specitivity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and plot ROC curve\n",
    "fpr, tpr, threshold = metrics.roc_curve(np.array(predictions_formatted).flatten(), np.array(ground_truth_formatted).flatten())\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('ROC_curve.jpg', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_mask(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(test_preds[i], axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cetting values to rows and column variables\n",
    "rows = 2\n",
    "columns = 3\n",
    "\n",
    "# Create figure\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=columns, figsize=(22, 15))\n",
    "row = 0\n",
    "\n",
    "for i in [1, 7]:\n",
    "    \n",
    "    column = 0\n",
    "    \n",
    "    # Plot images\n",
    "    axs[row, column].imshow(load_img(test_input_img_paths[i], target_size=img_size))\n",
    "    axs[row, column].set_title(\"Original image\")\n",
    "    column+=1\n",
    "    \n",
    "    axs[row, column].imshow(load_img(test_target_img_paths[i],  target_size=img_size), cmap='gray')\n",
    "    axs[row, column].set_title(\"Segmentation mask\")\n",
    "    column+=1\n",
    "    \n",
    "    axs[row, column].imshow(adapt_mask(i), cmap='gray')\n",
    "    axs[row, column].set_title(\"Predicted segmentation mask\")\n",
    "    column+=1\n",
    "    row+=1\n",
    "\n",
    "plt.savefig('Predicted segmantation masks.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "# Flatten predictions and ground truth for evaluation\n",
    "flat_predictions = np.array(predictions_formatted).flatten()\n",
    "flat_ground_truth = np.array(ground_truth_formatted).flatten()\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(flat_ground_truth, flat_predictions, target_names=['No Lesion', 'Lesion'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# You can also generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(flat_ground_truth, flat_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thushar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
